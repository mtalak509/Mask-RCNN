import streamlit as st
from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import requests
from io import BytesIO


st.set_page_config(page_title="–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü YOLO", page_icon="üëÅÔ∏è", layout="wide")
st.title("–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é –ª—é–±–æ–π –≤–µ—Ä—Å–∏–∏ YOLOv8 c –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –º–∞—Å–∫–∏—Ä–æ–≤–∫–æ–π –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏")
st.markdown("–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü –∏ —Ä–∞–∑–º—ã–≤–∞–Ω–∏—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π.")


# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

@st.cache_resource
def load_model():
    model = YOLO(r"models\face_model\train\weights\best.pt")
    return model

model = load_model()


with st.expander("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏–∏"):
    st.markdown("""
    **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** YOLOv8n
    - **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö:** 30
    - **–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏:** 16 000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    - **–ú–µ—Ç—Ä–∏–∫–∏:**
    - Precision (P): 0.90
    - Recall (R): 0.78
    - mAP@0.5: 0.855
    - mAP@0.5:0.95: 0.566

    **PR-–∫—Ä–∏–≤–∞—è –∏ confusion matrix:**
    """)
    col1, col2 = st.columns(2)
    with col1:
        st.image(r"models\face_model\train\results.png", caption="–ú–µ—Ç—Ä–∏–∫–∏", use_column_width=True)
    with col2:
        st.image(r"models\face_model\train\confusion_matrix.png", caption="Confusion matrix", use_column_width=True)

st.markdown("---")


st.subheader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ —Å—Å—ã–ª–∫—É")

uploaded_files = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True
)

url_input = st.text_input("–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ URL:")

images = []

# --- –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤—ë–ª —Å—Å—ã–ª–∫—É ---
if url_input:
    try:
        response = requests.get(url_input)
        image = Image.open(BytesIO(response.content)).convert("RGB")
        images.append(image)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Å—Å—ã–ª–∫–µ: {e}")

# --- –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∑–∏–ª —Ñ–∞–π–ª—ã ---
for uploaded in uploaded_files:
    image = Image.open(uploaded).convert("RGB")
    images.append(image)


if images:
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏:")

    for idx, image in enumerate(images):
        st.markdown(f"### –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx + 1}")
        img_np = np.array(image)

        # YOLO-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        results = model(img_np)

        # –†–∞–∑–º—ã—Ç–∏–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
        for r in results:
            for box in r.boxes.xyxy:
                x1, y1, x2, y2 = map(int, box)
                face_region = img_np[y1:y2, x1:x2]
                if face_region.size > 0:
                    face_region = cv2.GaussianBlur(face_region, (51, 51), 30)
                    img_np[y1:y2, x1:x2] = face_region

        # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–º–∫–∞–º–∏
        annotated = results[0].plot()
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–∞–∑–º—ã—Ç–∏–µ –∏ —Ä–∞–º–∫–∏
        blended = cv2.addWeighted(img_np, 0.8, annotated, 0.2, 0)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ RGB
        blended_rgb = cv2.cvtColor(blended, cv2.COLOR_BGR2RGB)

        st.image(blended_rgb, caption="–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏—è", use_column_width=True)

        st.markdown(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–∏—Ü: **{len(results[0].boxes)}**")
        st.markdown("---")

else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É, —á—Ç–æ–±—ã –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é.")
